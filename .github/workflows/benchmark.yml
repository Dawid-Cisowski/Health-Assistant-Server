name: AI Benchmark Tests

on:
  schedule:
    # Run every Monday at 6:00 AM UTC
    - cron: '0 6 * * 1'
  workflow_dispatch:
    inputs:
      models:
        description: 'Comma-separated list of models to benchmark'
        required: false
        default: 'gemini-2.0-flash,gemini-2.5-pro-preview-05-06'
        type: string

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: gradle

      - name: Grant execute permission for gradlew
        run: chmod +x gradlew

      - name: Run AI Benchmark Tests
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          BENCHMARK_MODELS: ${{ github.event.inputs.models || 'gemini-2.0-flash,gemini-2.5-pro-preview-05-06' }}
        run: ./gradlew :integration-tests:benchmarkTest --no-daemon

      - name: Display Benchmark Summary
        if: always()
        run: |
          if [ -f integration-tests/build/reports/benchmark/benchmark-report.md ]; then
            cat integration-tests/build/reports/benchmark/benchmark-report.md >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Benchmark report not generated" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Benchmark Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-reports-${{ github.run_number }}
          path: |
            integration-tests/build/reports/benchmark/
          retention-days: 90

      - name: Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-test-results-${{ github.run_number }}
          path: |
            integration-tests/build/reports/tests/benchmarkTest/
          retention-days: 30
